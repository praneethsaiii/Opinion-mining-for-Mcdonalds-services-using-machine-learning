pre
t=pre==test$polarity
table(t)
print(dctree)
plot(dctree)
#plot(pre)
table(pre)
accuracy1=mean(pre == test[ , 3])*100
accuracy=accuracy+accuracy1
print("Round Accuracy:")
print(accuracy1)
str(data)
df<-read.csv("sentimentdata.csv")
data<-data.frame(df)
accuracy=0
library(Amelia)
missmap(data, main = "Missing values vs observed")
str(data)
pd=sample(2,nrow(data),replace=TRUE,prob=c(0.9,0.1))
train=data[pd==1,]
test=data[pd==2,]
dctree <- ctree((polarity ~ emotion) , data=train)
pre=predict(dctree,test)
pre
t=pre==test$polarity
table(t)
plot(pre)
print(dctree)
plot(dctree)
accuracy1=mean(pre == test[ , 3])*100
print("Round Accuracy:")
print(accuracy1)
write.csv(pre,file="sentimentdata.csv")
sentimentdata <- read.csv("~/projeTest/sentimentdata.csv")
View(sentimentdata)
write.csv(pre,file="decpre.csv")
decpre <- read.csv("~/projeTest/decpre.csv")
View(decpre)
decpre <- read.csv("~/projeTest/decpre.csv")
View(decpre)
pctree <- ctree((emotion ~ polarity) , data=train)
pre=predict(pctree,test)
pre
t=pre==test$emotion
table(t)
print(pctree)
plot(pctree)
table(pre)
library(e1071)
data <- read.csv("sentimentanalysis.csv")
str(data)
str(data)
letter_classifier <- ksvm(emotion ~ ., data = train,
kernel = "vanilladot")
print(letter_classifier)
class(letter_classifier)
letter_predictions <- predict(letter_classifier, test)
head(letter_predictions)
table(letter_predictions, test$emotion)
agreement <- letter_predictions == test$emotion
table(agreement)
prop.table(table(agreement))
barplot(table(letter_predictions))
data <- read.csv("sentimentdata.csv")
str(data)
train <- data[1:1200, ]
test <- data[1201:1525, ]
library(kernlab)
letter_classifier <- ksvm(emotion ~ ., data = train,
kernel = "vanilladot")
print(letter_classifier)
class(letter_classifier)
letter_predictions <- predict(letter_classifier, test)
head(letter_predictions)
table(letter_predictions, test$emotion)
agreement <- letter_predictions == test$emotion
table(agreement)
prop.table(table(agreement))
barplot(table(letter_predictions))
accuracy1=mean(agreement)*100
print("Round Accuracy:")
print(accuracy1)
data <- read.csv("sentimentanalysis.csv")
str(data)
train <- data[1:1200, ]
test <- data[1201:1525, ]
library(kernlab)
letter_classifier <- ksvm(emotion ~ ., data = train,
kernel = "vanilladot")
print(letter_classifier)
class(letter_classifier)
letter_predictions <- predict(letter_classifier, test)
head(letter_predictions)
table(letter_predictions, test$emotion)
agreement <- letter_predictions == test$emotion
table(agreement)
prop.table(table(agreement))
barplot(table(letter_predictions))
accuracy1=mean(agreement)*100
print("Round Accuracy:")
print(accuracy1)
library(e1071)
data <- read.csv("sentimentanalysis.csv")
str(data)
train <- data[1:1200, ]
test <- data[1201:1525, ]
library(kernlab)
letter_classifier <- ksvm(emotion ~ ., data = train,
kernel = "vanilladot")
print(letter_classifier)
class(letter_classifier)
letter_predictions <- predict(letter_classifier, test)
head(letter_predictions)
table(letter_predictions, test$emotion)
agreement <- letter_predictions == test$emotion
table(agreement)
prop.table(table(agreement))
barplot(table(letter_predictions))
accuracy1=mean(agreement)*100
print("Round Accuracy:")
print(accuracy1)
library(e1071)
data <- read.csv("sentimentanalysis.csv")
str(data)
train <- data[1:1200, ]
test <- data[1201:1525, ]
library(kernlab)
letter_classifier <- ksvm(emotion ~ ., data = train,
kernel = "vanilladot")
print(letter_classifier)
class(letter_classifier)
letter_predictions <- predict(letter_classifier, test)
head(letter_predictions)
table(letter_predictions, test$emotion)
agreement <- letter_predictions == test$emotion
table(agreement)
prop.table(table(agreement))
barplot(table(letter_predictions))
accuracy1=mean(agreement)*100
print("Round Accuracy:")
print(accuracy1)
sentimentanalysis <- read.csv("~/projeTest/sentimentanalysis.csv")
View(sentimentanalysis)
library(e1071)
data <- read.csv("sentimentanalysis.csv")
str(data)
train <- data[1:1200, ]
test <- data[1201:1525, ]
library(kernlab)
letter_classifier <- ksvm(emotion ~ ., data = train,
kernel = "vanilladot")
print(letter_classifier)
class(letter_classifier)
plot(letter_classifier,train[,6])
plot(letter_classifier)
plot(factor(letter_classifier))
forummall <- read.csv("~/projeTest/branches/forummall.csv", sep="")
View(forummall)
library(tm)
library(NLP)
library(e1071)
library(Rstem)
library(stringr)
library(sentiment)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
data<-readLines("forummall.txt")
df <- data.frame(data)
data<-readLines("projetest\\forummall.txt")
data<-readLines("branches\\forummall.txt")
df <- data.frame(data)
library(Amelia)
missmap(df, main = "Missing values vs observed")
textdata <- df[df$data, ]
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub('[[:cntrl:]]', "", textdata)
textdata = gsub("[[:digit:]]", "", textdata)
textdata = gsub("http\\w+", "", textdata)
textdata = gsub("[ \t]{2,}", "", textdata)
textdata = gsub("^\\s+|\\s+$", "", textdata)
textdata = tolower(textdata)
try.error = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
textdata = sapply(textdata, try.error)
textdata = textdata[!is.na(textdata)]
names(textdata) = NULL
write.csv(textdata,file="pre.csv")
class_emo = classify_emotion(textdata, algorithm="bayes")
emotion = class_emo[,7]
emotion[is.na(emotion)] = "unknown"
class_pol = classify_polarity(textdata, algorithm="bayes")
polarity = class_pol[,4]
sent_df = data.frame(text=textdata, emotion=emotion,polarity=polarity, stringsAsFactors=FALSE)
sent_df = within(sent_df,emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="")
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="polarity categories", y="")
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep("", nemo)
for (i in 1:nemo)
{
tmp = textdata[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=" ")
}
emo.docs = removeWords(emo.docs, stopwords("english"))
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = emos
comparison.cloud(tdm, colors = brewer.pal(nemo, "Dark2"),
scale = c(3,.8), random.order = FALSE,
title.size = 1.5)
library(tm)
library(NLP)
library(e1071)
library(Rstem)
library(stringr)
library(sentiment)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
data<-readLines("branches\\malleshwaram.txt")
df <- data.frame(data)
library(Amelia)
missmap(df, main = "Missing values vs observed")
textdata <- df[df$data, ]
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub('[[:cntrl:]]', "", textdata)
textdata = gsub("[[:digit:]]", "", textdata)
textdata = gsub("http\\w+", "", textdata)
textdata = gsub("[ \t]{2,}", "", textdata)
textdata = gsub("^\\s+|\\s+$", "", textdata)
textdata = tolower(textdata)
# textdata<-Corpus(VectorSource(data))
# textdata<-tm_map(textdata,removeWords,stopwords(kind = "en"))
# textdata<-tm_map(textdata,stemDocument)
try.error = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
textdata = sapply(textdata, try.error)
textdata = textdata[!is.na(textdata)]
names(textdata) = NULL
class_emo = classify_emotion(textdata, algorithm="bayes")
emotion = class_emo[,7]
emotion[is.na(emotion)] = "unknown"
class_pol = classify_polarity(textdata, algorithm="bayes")
polarity = class_pol[,4]
sent_df = data.frame(text=textdata, emotion=emotion,polarity=polarity, stringsAsFactors=FALSE)
sent_df = within(sent_df,emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="")
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="polarity categories", y="")
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep("", nemo)
for (i in 1:nemo)
{
tmp = textdata[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=" ")
}
emo.docs = removeWords(emo.docs, stopwords("english"))
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = emos
comparison.cloud(tdm, colors = brewer.pal(nemo, "Dark2"),
scale = c(3,.8), random.order = FALSE,
title.size = 1.5)
library(tm)
library(NLP)
library(e1071)
library(Rstem)
library(stringr)
library(sentiment)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
data<-readLines("branches\\lidomall.txt")
df <- data.frame(data)
library(Amelia)
missmap(df, main = "Missing values vs observed")
textdata <- df[df$data, ]
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub('[[:cntrl:]]', "", textdata)
textdata = gsub("[[:digit:]]", "", textdata)
textdata = gsub("http\\w+", "", textdata)
textdata = gsub("[ \t]{2,}", "", textdata)
textdata = gsub("^\\s+|\\s+$", "", textdata)
textdata = tolower(textdata)
# textdata<-Corpus(VectorSource(data))
# textdata<-tm_map(textdata,removeWords,stopwords(kind = "en"))
# textdata<-tm_map(textdata,stemDocument)
try.error = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
textdata = sapply(textdata, try.error)
textdata = textdata[!is.na(textdata)]
names(textdata) = NULL
class_emo = classify_emotion(textdata, algorithm="bayes")
emotion = class_emo[,7]
emotion[is.na(emotion)] = "unknown"
class_pol = classify_polarity(textdata, algorithm="bayes")
polarity = class_pol[,4]
sent_df = data.frame(text=textdata, emotion=emotion,polarity=polarity, stringsAsFactors=FALSE)
sent_df = within(sent_df,emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="")
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="polarity categories", y="")
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep("", nemo)
for (i in 1:nemo)
{
tmp = textdata[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=" ")
}
emo.docs = removeWords(emo.docs, stopwords("english"))
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = emos
comparison.cloud(tdm, colors = brewer.pal(nemo, "Dark2"),
scale = c(3,.8), random.order = FALSE,
title.size = 1.5)
library(tm)
library(NLP)
library(e1071)
library(Rstem)
library(ggplot2)
library(RCurl)
library(ggmap)
library(xml2)
library(sentiment)
library(RTextTools)
library(RColorBrewer)
library(class)
library(gmodels)
library(MASS)
data<-read.csv("test.csv")
matrix= create_matrix(data$review, language="english",
removeStopwords=TRUE, removeNumbers=TRUE,
stemWords=TRUE)
container = create_container(matrix, as.numeric(as.factor(data[,1])),
trainSize=1:1300, testSize=1301:1513,virgin=FALSE)
models = train_models(container, algorithms="SVM")
results = classify_models(container, models)
results
table(as.numeric(as.factor(data[1301:1513, 2])), results[,"SVM_LABEL"])
plot(results)
plot(container,results)
plot(results,container)
plot(accuracy1)
barplot(accuracy1)
library(party)
df<-read.csv("sentimentdata.csv")
data<-data.frame(df)
library(Amelia)
missmap(data, main = "Missing values vs observed")
str(data)
pd=sample(2,nrow(data),replace=TRUE,prob=c(0.9,0.1))
train=data[pd==1,]
test=data[pd==2,]
dctree <- ctree((polarity ~ emotion) , data=train)
pre=predict(dctree,test)
pre
t=pre==test$polarity
table(t)
print(dctree)
plot(dctree)
plot(pre)
table(pre)
accuracy1=mean(pre == test[ , 3])*100
print("Round Accuracy:")
print(accuracy1)
write.csv(pre,file="decpre.csv")
library(e1071)
library(neuralnet)
data<-data.csv("sentimentdata.csv")
data<-read.csv("sentimentdata.csv")
str(data)
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
concrete_norm <- as.data.frame(lapply(data, normalize))
summary(concrete_norm$emotion)
concrete_train <- data[1:1200, ]
concrete_test <- data[1201:1525, ]
concrete_model <- neuralnet(emotion ~ polarity,data = concrete_train)
concrete_model <- neuralnet(as.factor(emotion) ~ as.factor(polarity),data = concrete_train)
concrete_model <- neuralnet((as.numeric(factor(emotion))) ~ (as.numeric(factor(polarity))),data = concrete_train)
plot(concrete_model)
install.packages("frbs")
install.packages("sets")
install.packages("fuzzySim", repos = "http://R-Forge.R-project.org")
library(sets)
U1 <- seq(from = 0, to = 1, by = 0.0001)
#DIMENSIONS
variables <-
set(
code =
fuzzy_partition(varnames=
c(ELow = 0.2 , ENormal = 0.5, EHigh = 0.8),
FUN= fuzzy_cone, radius = 0.2, universe=U1),
bandwidth =
fuzzy_partition(varnames=
c(SLow = 0.2, SNormal=0.5, SHigh=0.8),
FUN = fuzzy_cone, radius = 0.2, universe=U1),
acceleration =
fuzzy_partition(varnames=
c(ALow = 0.2, ANormal=0.5, AHigh=0.8),
FUN = fuzzy_cone, radius = 0.2, universe=U1),
processing =
fuzzy_partition(varnames=
c(Local = 0.3, Remote = 0.7),
FUN = fuzzy_cone, radius = 0.3, universe=U1)
)
rules <-
set(
fuzzy_rule(code %is% EHigh && bandwidth %is% SHigh && acceleration %is% AHigh, processing %is% Remote),
fuzzy_rule(code %is% EHigh && bandwidth %is% SHigh && acceleration %is% ANormal, processing %is% Remote),
fuzzy_rule(code %is% EHigh && bandwidth %is% SHigh && acceleration %is% ALow, processing %is% Local),
fuzzy_rule(code %is% EHigh && bandwidth %is% SNormal && acceleration %is% AHigh, processing %is% Remote),
fuzzy_rule(code %is% EHigh && bandwidth %is% SNormal && acceleration %is% ANormal, processing %is% Remote),
fuzzy_rule(code %is% EHigh && bandwidth %is% SNormal && acceleration %is% ALow, processing %is% Local),
fuzzy_rule(code %is% EHigh && bandwidth %is% SLow && acceleration %is% AHigh, processing %is% Remote),
fuzzy_rule(code %is% EHigh && bandwidth %is% SLow && acceleration %is% ANormal, processing %is% Local),
fuzzy_rule(code %is% EHigh && bandwidth %is% SLow && acceleration %is% ALow, processing %is% Local),
fuzzy_rule(code %is% EHigh && bandwidth %is% SHigh, processing %is% Remote),
fuzzy_rule(code %is% EHigh && bandwidth %is% SLow, processing %is% Local),
fuzzy_rule(code %is% EHigh && bandwidth %is% SNormal, processing %is% Local),
fuzzy_rule(code %is% ENormal && bandwidth %is% SLow, processing %is% Local),
fuzzy_rule(code %is% ENormal && bandwidth %is% SHigh, processing %is% Remote),
fuzzy_rule(code %is% ENormal && bandwidth %is% SNormal, processing %is% Local),
fuzzy_rule(code %is% ELow && bandwidth %is% SLow, processing %is% Local),
fuzzy_rule(code %is% ELow && bandwidth %is% SNormal, processing %is% Local),
fuzzy_rule(code %is% ELow && bandwidth %is% SHigh, processing %is% Local)
)
context <- fuzzy_system(variables, rules)
print(context)
#plot(context)
#fi <- fuzzy_inference(context, list(code=0.8123, bandwidth=0.912))
#0.7
#fi <- fuzzy_inference(context, list(code=0.5212, bandwidth=0.2121))
#0.3
#fi <- fuzzy_inference(context, list(code=0.1532, bandwidth=0.9321))
#0.3
#fi <- fuzzy_inference(context, list(code=0.2432, bandwidth=0.9323))
#0.3
#fi <- fuzzy_inference(context, list(code=0.4723, bandwidth=0.9542))
#0.7
#fi <- fuzzy_inference(context, list(code=0.2932, bandwidth=0.9484))
#0.3
#fi <- fuzzy_inference(context, list(code=0.2912, bandwidth=0.4324))
#0.3
#fi <- fuzzy_inference(context, list(code=0.2134, bandwidth=0.2194))
#0.3
#fi <- fuzzy_inference(context, list(code=0.4323, bandwidth=0.5345))
#0.3
#fi <- fuzzy_inference(context, list(code=0.8123, bandwidth=0.912, acceleration = NA))
#There is a rule code is High AND bandwidth is High -> Remote.
#as well as a rule, code is High AND bandwidth is High and acceleration is High -> Remote.
#0.7
#fi <- fuzzy_inference(context, list(code=0.8123, bandwidth=0.912, acceleration = 0.93))
#0.7
#fi <- fuzzy_inference(context, list(code=0.8123, bandwidth=0.912, acceleration = 0.13))
#0.5
#fi <- fuzzy_inference(context, list(code=0.8123, bandwidth=0.2354, acceleration = 0.9243))
#0.4517523
#fi <- fuzzy_inference(context, list(code=0.4723, bandwidth=0.9542, acceleration=NA))
#This rule exists for the two variables provided
#0.7
#fi <- fuzzy_inference(context, list(code=0.8857, bandwidth=0.1194, acceleration=0.8921))
#0.4961897
fi <- fuzzy_inference(context, list(code=0.8857, bandwidth=0.1194, acceleration=0.1184))
#0.3
#dev.new()
#plot(fi)
gset_defuzzify(fi, "centroid")
U1 <- NULL
